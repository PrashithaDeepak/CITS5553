{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ad-N9KMeHcsc",
        "outputId": "bd6eb000-37e0-4f45-b21f-7803ede1a55b"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def analyze_documents(folder_path,target_pdf,n):\n",
        "    import os\n",
        "    import json\n",
        "    import numpy as np\n",
        "    import nltk\n",
        "    from nltk.tokenize import word_tokenize\n",
        "    from nltk.corpus import stopwords as sw\n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "    from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "    # Downloading required NLTK packages\n",
        "    nltk.download('punkt', quiet=True)\n",
        "    nltk.download('stopwords', quiet=True)\n",
        "\n",
        "\n",
        "\n",
        "    ### Nested functions:\n",
        "\n",
        "    #process input text\n",
        "    n = int(n)\n",
        "\n",
        "    # Processing the text data\n",
        "    def process_text(text):\n",
        "        tokens = word_tokenize(text)\n",
        "        stopwords = set(sw.words('english'))\n",
        "        tokens = [token for token in tokens if token.lower() not in stopwords]\n",
        "        return ' '.join(tokens)\n",
        "\n",
        "    # Function to get the top n similar documents\n",
        "    def get_top_n_similar_documents(index, similarity_matrix, n=5):\n",
        "        # Getting similarity values for the given document with all other documents\n",
        "        similarity_values = similarity_matrix[index]\n",
        "\n",
        "        # Sorting the indices based on similarity values in descending order\n",
        "        sorted_indices = np.argsort(similarity_values)[::-1]\n",
        "\n",
        "        # Excluding the first index because it will be the given document itself (similarity with itself is 1)\n",
        "        return sorted_indices[1:n+1]\n",
        "\n",
        "    \n",
        "    file_list = os.listdir(folder_path)\n",
        "    # Creating list to hold documents' contents\n",
        "    documents = []\n",
        "\n",
        "    # Creating list to hold corresponding PDF filenames\n",
        "    pdf_file_list = []\n",
        "\n",
        "    # Loading the JSON files and extracting content\n",
        "    for file_name in file_list:\n",
        "        if file_name.endswith('.json'):                      # Checking if the file is a JSON file\n",
        "            with open(os.path.join(folder_path, file_name), 'r') as file:\n",
        "                data = json.load(file)\n",
        "                abstract = data.get(\"SHORT_ABSTRACT\", \"\")    # Using the information in the short abstract & title sections to represent the content of the documents\n",
        "                documents.append(process_text(abstract))\n",
        "                pdf_filename = data.get(\"pdf_files\", [None])[0]   # Getting the corresponding PDF filename\n",
        "                if pdf_filename:                             # Appendding the PDF filename to pdf_file_list\n",
        "                    pdf_file_list.append(pdf_filename)\n",
        "\n",
        "    vectorizer = TfidfVectorizer()                           # Using TF-IDF to vectorize the processed content\n",
        "    tfidf_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "    # similarity_matrix[i][j] gives the cosine similarity between the i-th and j-th document\n",
        "    similarity_matrix = cosine_similarity(tfidf_matrix)\n",
        "        # Initialize an empty result string\n",
        "    result = \"\"\n",
        "        \n",
        "    if target_pdf in pdf_file_list:\n",
        "        # Choosing a document index for the target PDF\n",
        "        document_index = pdf_file_list.index(target_pdf)\n",
        "\n",
        "        # Getting the top n similar document indices\n",
        "        top_n_indices = get_top_n_similar_documents(document_index, similarity_matrix, n)\n",
        "\n",
        "        # Append target PDF's SHORT_ABSTRACT to the result\n",
        "        result += f\"\\nTarget PDF's SHORT_ABSTRACT:\\n{documents[document_index]}\\n\"\n",
        "\n",
        "        # Append the top n similar documents to the result\n",
        "        result += f\"\\nTop {n} similar documents to {target_pdf} are:\\n\"\n",
        "        for i in top_n_indices:\n",
        "            result += f\"\\nPDF Name: {pdf_file_list[i]}\\nSHORT_ABSTRACT: {documents[i]}\\n\"\n",
        "    else:\n",
        "        result = f\"'{target_pdf}' not found in pdf_file_list.\"\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/8y/ch4m12w15h791t1xbv7k64v40000gn/T/ipykernel_16961/350477344.py:9: GradioUnusedKwargWarning: You have unused kwarg parameters in Number, please remove them: {'default': 3, 'min': 1, 'max': 100}\n",
            "  gr.Number(label=\"Please enter the number of top similar documents to retrieve:\", default=3, min=1, max=100, step=1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7919\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7919/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=analyze_documents,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Please enter the folder path:\", placeholder=\"Enter Folder path\"),\n",
        "        gr.Textbox(label=\"Please enter the name of the target PDF:\", placeholder=\"Enter Filename\"),\n",
        "        gr.Number(label=\"Please enter the number of top similar documents to retrieve:\", default=3, min=1, max=100, step=1)\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Similar Files\"),\n",
        "    examples=[\n",
        "        [\"/content/drive/MyDrive/CITS5553_Group 5/wamex_metadata/subset_1\",\"a071228_051017_baldivis_minexpreport_10321296.pdf\", 3],[\"/content/drive/MyDrive/CITS5553_Group 5/wamex_metadata/subset_1\",\"a071874_700-100-go-rep-0005_11545981.pdf\", 3]],\n",
        "    title=\"Similarity Generator\"\n",
        ")\n",
        "\n",
        "demo.launch()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
